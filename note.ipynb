{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 优化器\n",
    "在CIFAR-10分类任务中，可以使用多种优化器来训练模型。根据搜索结果，以下是一些常用的优化器：\n",
    "\n",
    "1. **SGD（随机梯度下降）**：这是一个非常传统的优化器，也是最基本的优化算法。SGD通过使用一个小批量的样本来计算梯度，并根据这些梯度来更新模型的参数。SGD的优点是简单易用，计算开销小。但缺点是容易陷入局部最优，且在训练后期震荡较大。SGD适用于简单的网络结构或作为复杂优化算法的基础。在PyTorch中，SGD的使用方法如下：\n",
    "   ```python\n",
    "   optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "   ```\n",
    "   其中`model.parameters()`表示要优化的模型参数，`lr`是学习率。\n",
    "\n",
    "2. **Adam**：Adam优化器结合了RMSProp和动量法的思想，通过自适应调整学习率，同时维护了动量的一阶和二阶矩估计。Adam的优点是适应性强，对不同类型的数据表现良好；对超参数不太敏感，默认参数通常效果不错。缺点是有可能会陷入局部最优且收敛慢，特别是在大规模数据集上。Adam广泛应用于各种深度学习任务，是目前最常用的优化器之一。在PyTorch中，Adam的使用方法如下：\n",
    "   ```python\n",
    "   optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "   ```\n",
    "   其中`model.parameters()`表示要优化的模型参数，`lr`是学习率。\n",
    "\n",
    "3. **AdamW**：AdamW是Adam的一种改进版本，在每次参数更新时加入了权重衰减（weight decay）来防止模型过拟合。AdamW与L2正则化相比效果更好，能更好地防止过拟合。相较Adam略复杂，但总体使用体验较好。常用于Transformer等需要精细调参的深度学习模型。\n",
    "\n",
    "4. **Momentum**：Momentum优化器是SGD的一种扩展，它引入了动量的概念，可以帮助优化器在相关方向上加速，在不相关的方向上抑制震荡。\n",
    "\n",
    "5. **RMSprop**：RMSprop是一种自适应学习率的优化器，它通过调整每个参数的学习率来加速收敛。RMSprop适用于处理非平稳目标的情况。\n",
    "\n",
    "6. **Adagrad**：Adagrad是一种自适应学习率的优化器，它通过增加之前已经更新过很多次的参数的学习率来减少其影响。Adagrad适用于稀疏数据。\n",
    "\n",
    "7. **Adadelta**：Adadelta是Adagrad的改进版本，它解决了Adagrad学习率积累的问题，适用于非平稳目标和有噪声的数据。\n",
    "\n",
    "在实际应用中，选择哪种优化器取决于具体的任务、数据集和模型结构。有时需要通过实验来确定最佳的优化器和其超参数。\n"
   ],
   "id": "5cd77328300ce515"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 评价指标\n",
    "在CIFAR-10分类任务中，常用的评价指标包括：\n",
    "\n",
    "1. **准确率（Accuracy）**：这是最常用的评价指标，表示模型正确分类的样本数占总样本数的比例。在CIFAR-10数据集中，准确率通常用来衡量模型的性能，高准确率意味着模型具有较好的分类能力。\n",
    "\n",
    "2. **混淆矩阵（Confusion Matrix）**：混淆矩阵是一个表格，用于描述分类模型的性能。它显示了每个类别的预测值与实际值之间的关系，包括真正例（TP）、假正例（FP）、真负例（TN）和假负例（FN）。\n",
    "\n",
    "3. **精确率（Precision）**：精确率是指模型预测为正类别中实际为正类别的比例，计算公式为 TP / (TP + FP)。\n",
    "\n",
    "4. **召回率（Recall）**：召回率是指实际为正类别中被模型正确预测为正类别的比例，计算公式为 TP / (TP + FN)。\n",
    "\n",
    "5. **F1分数（F1 Score）**：F1分数是精确率和召回率的调和平均数，用于衡量模型的准确性和完整性的平衡，计算公式为 2 * (Precision * Recall) / (Precision + Recall)。\n",
    "\n",
    "6. **损失函数值（Loss）**：在训练过程中，损失函数值用于衡量模型预测值与实际值之间的差异。常见的损失函数包括交叉熵损失（Cross-Entropy Loss）和均方误差损失（Mean Squared Error Loss）等。\n",
    "\n",
    "7. **AUC-ROC曲线**：AUC-ROC曲线用于衡量分类模型的性能，特别是在二分类问题中。AUC（Area Under the Curve）值越接近1，表示模型的分类能力越强。\n",
    "\n",
    "8. **Top-k准确率（Top-k Accuracy）**：在多分类问题中，Top-k准确率表示模型预测的前k个最可能的类别中是否包含了真实类别。\n",
    "\n",
    "在实际应用中，通常会根据具体任务的需求和数据集的特点选择合适的评价指标。例如，在CIFAR-10数据集上，通常会关注模型的准确率和损失函数值，同时也会通过混淆矩阵来分析模型在各个类别上的表现，以及通过精确率、召回率和F1分数来进一步评估模型的性能。\n"
   ],
   "id": "49839b17a0ec7e0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "77eeac516c14d101"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
